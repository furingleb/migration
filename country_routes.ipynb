{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Файлы__:\n",
    "* файлы с id городов, распределенных по странам ___(e. g. Russia.txt)___, где строка - _id,title_ (список с названиями стран СНГ - _cis_countries_);\n",
    "* файлы с маршрутами ___(all_routes.csv)___ со столбцами _type_, _route_, _num_;\n",
    "* файл с уникальными городами ___(cities_ids.txt)___, где строка - _id,title_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открываем файл со всеми путями, распределенными по полу и типу перемещения, создаем соответствующие датафреймы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv('all_routes.csv', sep='\\t')\n",
    "\n",
    "df_work = df_[df_['type'] == 'work']\n",
    "df_school = df_[df_['type'] == 'school']\n",
    "df_stou = df_[df_['type'] == 'school_to_university']\n",
    "df_university = df_[df_['type'] == 'university']\n",
    "df_full = df_[df_['type'] == 'full']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем данные на сами маршруты и их количество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_work_route = list(df_work['route'])\n",
    "routes_school_route = list(df_school['route'])\n",
    "routes_stou_route = list(df_stou['route'])\n",
    "routes_university_route = list(df_university['route'])\n",
    "routes_full_route = list(df_full['route'])\n",
    "\n",
    "routes_work_num = list(df_work['num'])\n",
    "routes_school_num = list(df_school['num'])\n",
    "routes_stou_num = list(df_stou['num'])\n",
    "routes_university_num = list(df_university['num'])\n",
    "routes_full_num = list(df_full['num'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открываем списки городов каждой страны и заменяем каждый город в каждом маршруте на страну, которой он принадлежит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_countries_routes(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as country_file:\n",
    "        country_cities = country_file.read().split('\\n')\n",
    "        cities = []\n",
    "        del country_cities[-1]\n",
    "        for i in country_cities:\n",
    "            id_title = i.split(',')\n",
    "            cities.append(id_title[0]) \n",
    "    return cities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "russia = make_countries_routes('Russia.txt')\n",
    "\n",
    "armenia = make_countries_routes('Armenia.txt')\n",
    "azerbaijan = make_countries_routes('Azerbaijan.txt')\n",
    "belarus = make_countries_routes('Belarus.txt')\n",
    "kazakhstan = make_countries_routes('Kazakhstan.txt')\n",
    "kyrgyzstan = make_countries_routes('Kyrgyzstan.txt')\n",
    "moldova = make_countries_routes('Moldova.txt')\n",
    "tajikistan = make_countries_routes('Tajikistan.txt')\n",
    "turkmenistan = make_countries_routes('Turkmenistan.txt')\n",
    "ukraine = make_countries_routes('Ukraine.txt')\n",
    "uzbekistan = make_countries_routes('Uzbekistan.txt')\n",
    "georgia = make_countries_routes('Georgia.txt')\n",
    "\n",
    "latvia = make_countries_routes('Latvia.txt')\n",
    "lithuania = make_countries_routes('Lithuania.txt') \n",
    "estonia = make_countries_routes('Estonia.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saint_p.txt', 'r', encoding='utf-8') as leningrad:\n",
    "    leningrad_cities = leningrad.read().split('\\n')\n",
    "    \n",
    "with open('krasnodar.txt', 'r', encoding='utf-8') as krasnodar:\n",
    "    krasnodar_cities = krasnodar.read().split('\\n')\n",
    "    \n",
    "with open('moscow.txt', 'r', encoding='utf-8') as moscow:\n",
    "    moscow_cities = moscow.read().split('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_route_by_countries(city_routes, countries, country_names):\n",
    "    for country in tqdm(range(len(countries))):\n",
    "        for city_route in range(len(city_routes)):\n",
    "            cities = city_routes[city_route].split(', ')\n",
    "            route = []\n",
    "            for city in cities:\n",
    "                if city in countries[country]:\n",
    "                    route.append(country_names[country])\n",
    "                else:\n",
    "                    route.append(city)\n",
    "            route = ', '.join(route)\n",
    "            city_routes[city_route] = route\n",
    "    for i in range(len(city_routes)):\n",
    "        city_routes[i] = re.sub('-?[0-9]+', 'world', city_routes[i])\n",
    "    return city_routes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntrs = [leningrad_cities, krasnodar_cities, moscow_cities, russia, armenia, azerbaijan, belarus, georgia, kazakhstan, kyrgyzstan, moldova, tajikistan, turkmenistan, ukraine, uzbekistan, latvia, lithuania, estonia]\n",
    "cntrs_names = ['leningrad', 'krasnodar', 'moscow', 'russia', 'armenia', 'azerbaijan', 'belarus', 'georgia', 'kazakhstan', 'kyrgyzstan', 'moldova', 'tajikistan', 'turkmenistan', 'ukraine', 'uzbekistan', 'latvia', 'lithuania', 'estonia']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_routes = [routes_work_route, routes_school_route, routes_stou_route, routes_university_route, routes_full_route]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3c0d2248414eeeb5832767932a7aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a984e65d6cd843d7bb462c3a23b1322a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4189b23ac0aa44609e6f4be24593011a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f80fb22a1424b0a830e994696ba08c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d0df237cb7467d82fdbe4196533bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(all_routes)):\n",
    "    all_routes[i] = get_route_by_countries(all_routes[i], cntrs, cntrs_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем данные в csv-файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('country_routes.csv', 'a', encoding='utf-8') as csv_file:\n",
    "    file_writer = csv.writer(csv_file, delimiter = \"\\t\")\n",
    "    file_writer.writerow([\"type\", \"route\", 'num'])\n",
    "    for i in range(len(routes_work_route)):\n",
    "        file_writer.writerow(['work', routes_work_route[i], routes_work_num[i]])\n",
    "    for i in range(len(routes_school_route)):\n",
    "        file_writer.writerow(['school', routes_school_route[i], routes_school_num[i]])\n",
    "    for i in range(len(routes_stou_route)):\n",
    "        file_writer.writerow(['school_to_university', routes_stou_route[i], routes_stou_num[i]])\n",
    "    for i in range(len(routes_university_route)):\n",
    "        file_writer.writerow(['university', routes_university_route[i], routes_university_num[i]])\n",
    "    for i in range(len(routes_full_route)):\n",
    "        file_writer.writerow(['full', routes_full_route[i], routes_full_num[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открываем файл с перемещениями по странам и делаем словари вида 'путь: количество', соединяя повторяющиеся пути:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv('country_routes.csv', sep='\\t')\n",
    "\n",
    "df_work = df_[df_['type'] == 'work']\n",
    "df_school = df_[df_['type'] == 'school']\n",
    "df_stou = df_[df_['type'] == 'school_to_university']\n",
    "df_university = df_[df_['type'] == 'university']\n",
    "df_full = df_[df_['type'] == 'full']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(routes, nums):\n",
    "    routes_nums = {}\n",
    "    for i in range(len(routes)):\n",
    "        try:\n",
    "            routes_nums[routes[i]] += nums[i]\n",
    "        except:\n",
    "            routes_nums[routes[i]] = nums[i]\n",
    "    return routes_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = make_dict(list(df_work['route']), list(df_work['num']))\n",
    "rs = make_dict(list(df_school['route']), list(df_school['num']))\n",
    "rsu = make_dict(list(df_stou['route']), list(df_stou['num']))\n",
    "ru = make_dict(list(df_university['route']), list(df_university['num']))\n",
    "rf = make_dict(list(df_full['route']), list(df_full['num']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_double_countries(routes):\n",
    "    new_routes = {}\n",
    "    for k, v in routes.items():\n",
    "        key = k.split(', ')\n",
    "        new_key = [key[0]]\n",
    "        for i in range(1, len(key)):\n",
    "            if key[i] != new_key[-1]:\n",
    "                new_key.append(key[i])\n",
    "        try:\n",
    "            new_routes[', '.join(new_key)] += v\n",
    "        except:\n",
    "            new_routes[', '.join(new_key)] = v\n",
    "    return new_routes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = ['moscow', 'leningrad', 'krasnodar', 'russia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntrs_names = ['armenia','azerbaijan','belarus','georgia','kazakhstan','kyrgyzstan']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем идущие подряд одинаковые страны в каждом маршруте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rw = delete_double_countries(rw)\n",
    "unique_rs = delete_double_countries(rs)\n",
    "unique_rsu = delete_double_countries(rsu)\n",
    "unique_ru = delete_double_countries(ru)\n",
    "unique_rf = delete_double_countries(rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_values(dict1):\n",
    "    d = {k: dict1[k] for k in sorted(dict1, key=dict1.get, reverse=True)}\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достаем первые страны в каждом маршруте и складываем, чтобы потом узнать процентное соотношение людей из разных стран для корректного анализа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_country(country_routes_type):\n",
    "    first_countries = {}\n",
    "    for k, v in country_routes_type.items():\n",
    "        key = k.split(', ')\n",
    "        try:\n",
    "            first_countries[key[0]] += v\n",
    "        except:\n",
    "            first_countries[key[0]] = v\n",
    "    return first_countries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_country(country_routes_type):\n",
    "    first_countries = {}\n",
    "    for k, v in country_routes_type.items():\n",
    "        key = k.split(', ')\n",
    "        try:\n",
    "            first_countries[key[-1]] += v\n",
    "        except:\n",
    "            first_countries[key[-1]] = v\n",
    "    return first_countries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_rw = get_first_country(unique_rw)\n",
    "first_rs = get_first_country(unique_rs)\n",
    "first_rsu = get_first_country(unique_rsu)\n",
    "first_ru = get_first_country(unique_ru)\n",
    "first_rf = get_first_country(unique_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_rw = get_last_country(unique_rw)\n",
    "last_rs = get_last_country(unique_rs)\n",
    "last_rsu = get_last_country(unique_rsu)\n",
    "last_ru = get_last_country(unique_ru)\n",
    "last_rf = get_last_country(unique_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделываем то же самое, что и ранее, но обобщаем все страны СНГ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_names = ['armenia', 'azerbaijan', 'belarus', 'georgia', 'kazakhstan', 'kyrgyzstan', 'moldova', 'tajikistan', 'turkmenistan', 'ukraine', 'uzbekistan']\n",
    "baltics_names = ['latvia', 'lithuania', 'estonia']\n",
    "rus_names = ['leningrad', 'krasnodar', 'moscow']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cis_world_russia(cis_names, baltics_names, unique_srt):\n",
    "    new_routes = {}\n",
    "    for k, v in unique_srt.items():\n",
    "        key = k.split(', ')\n",
    "        new_key = []\n",
    "        for country in key:\n",
    "            if country in cis_names:\n",
    "                new_key.append('cis')\n",
    "            elif country in baltics_names:\n",
    "                new_key.append('baltics')\n",
    "            elif country in rus_names:\n",
    "                new_key.append('russia')\n",
    "            else:\n",
    "                new_key.append(country)\n",
    "        key_wo_doub = [new_key[0]]\n",
    "        for i in range(1, len(new_key)):\n",
    "            if new_key[i] != key_wo_doub[-1]:\n",
    "                key_wo_doub.append(new_key[i])\n",
    "        try:\n",
    "            new_routes[', '.join(key_wo_doub)] += v\n",
    "        except:\n",
    "            new_routes[', '.join(key_wo_doub)] = v\n",
    "    return new_routes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rucisbalt_rw = make_cis_world_russia(cis_names, baltics_names, unique_rw)\n",
    "rucisbalt_rs = make_cis_world_russia(cis_names, baltics_names, unique_rs)\n",
    "rucisbalt_rsu = make_cis_world_russia(cis_names, baltics_names, unique_rsu)\n",
    "rucisbalt_ru = make_cis_world_russia(cis_names, baltics_names, unique_ru)\n",
    "rucisbalt_rf = make_cis_world_russia(cis_names, baltics_names, unique_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова находим первое количество людей с тем или иным местом проживания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstc_rw = get_first_country(rucisbalt_rw)\n",
    "firstc_rs = get_first_country(rucisbalt_rs)\n",
    "firstc_rsu = get_first_country(rucisbalt_rsu)\n",
    "firstc_ru = get_first_country(rucisbalt_ru)\n",
    "firstc_rf = get_first_country(rucisbalt_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastc_rw = get_last_country(rucisbalt_rw)\n",
    "lastc_rs = get_last_country(rucisbalt_rs)\n",
    "lastc_rsu = get_last_country(rucisbalt_rsu)\n",
    "lastc_ru = get_last_country(rucisbalt_ru)\n",
    "lastc_rf = get_last_country(rucisbalt_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
